I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
INFO:tensorflow:PS hosts are: ['node1g4:2220']
INFO:tensorflow:Worker hosts are: ['node1g4:2230', 'node2g4:2230', 'node3g4:2230', 'node4g4:2230', 'node5g4:2230']
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:907] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 4.00GiB
Free memory: 3.92GiB
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:907] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:04.0
Total memory: 4.00GiB
Free memory: 3.92GiB
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:907] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:05.0
Total memory: 4.00GiB
Free memory: 3.92GiB
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:907] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 3 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:06.0
Total memory: 4.00GiB
Free memory: 3.92GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 2 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 2 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 2 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 3 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 3 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 3 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 2 3 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N N N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y N N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 2:   N N Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 3:   N N N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GRID K520, pci bus id: 0000:00:04.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GRID K520, pci bus id: 0000:00:05.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GRID K520, pci bus id: 0000:00:06.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {node1g4:2220}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:2230, node2g4:2230, node3g4:2230, node4g4:2230, node5g4:2230}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2230
INFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=5; total_num_replicas=5
INFO:tensorflow:2016-05-26 19:33:09.609820 Supervisor
E0526 19:33:26.599592485   48701 tcp_client_posix.c:173]     failed to connect to 'ipv4:172.31.15.42:2230': socket error: connection refused
E0526 19:33:27.600383878   48701 tcp_client_posix.c:173]     failed to connect to 'ipv4:172.31.15.42:2230': socket error: connection refused
E0526 19:33:29.136246481   48701 tcp_client_posix.c:173]     failed to connect to 'ipv4:172.31.15.42:2230': socket error: connection refused
INFO:tensorflow:Started 3 queues for processing input data.
INFO:tensorflow:global_step/sec: 0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 4163 get requests, put_count=2372 evicted_count=1000 eviction_rate=0.421585 and unsatisfied allocation rate=0.694451
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 100 to 110
INFO:tensorflow:Worker 0: 2016-05-26 19:34:28.982399: step 0, loss = 4.88(1.9 examples/sec; 12.668  sec/batch)
INFO:tensorflow:Worker 0: 2016-05-26 19:34:32.265242: step 0, loss = 4.86(7.3 examples/sec; 3.282  sec/batch)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 4063 get requests, put_count=3431 evicted_count=2000 eviction_rate=0.58292 and unsatisfied allocation rate=0.650997
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 146 to 160
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=2019 evicted_count=2000 eviction_rate=0.990589 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=2028 evicted_count=2000 eviction_rate=0.986193 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 4063 get requests, put_count=3763 evicted_count=2000 eviction_rate=0.531491 and unsatisfied allocation rate=0.575929
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 449 to 493
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=1065 evicted_count=1000 eviction_rate=0.938967 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 4063 get requests, put_count=3532 evicted_count=1000 eviction_rate=0.283126 and unsatisfied allocation rate=0.402658
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 1158 to 1273
INFO:tensorflow:global_step/sec: 0.177352
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 12189 get requests, put_count=12469 evicted_count=1000 eviction_rate=0.0801989 and unsatisfied allocation rate=0.0775289
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 2478 to 2725
INFO:tensorflow:Worker 0: 2016-05-26 19:36:51.371454: step 30, loss = 5.22(6.4 examples/sec; 3.765  sec/batch)
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:global_step/sec: 0.257668
INFO:tensorflow:Worker 0: 2016-05-26 19:38:47.328980: step 60, loss = 4.94(6.9 examples/sec; 3.472  sec/batch)
INFO:tensorflow:global_step/sec: 0.27574
INFO:tensorflow:Running Summary operation on the chief.
INFO:tensorflow:Finished running Summary operation.
INFO:tensorflow:Worker 0: 2016-05-26 19:40:35.513190: step 90, loss = 4.47(7.1 examples/sec; 3.369  sec/batch)
